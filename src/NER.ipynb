{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import config\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 50\n",
    "SPLIT = 0.8\n",
    "BATCH_SIZE = 100\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "EMBEDDING_DIM = 150\n",
    "HIDDEN_DIM = 256\n",
    "N_LAYERS = 2\n",
    "OUTPUT_SIZE = 1\n",
    "EPOCHS = 4\n",
    "PRINT_EVERY = 100\n",
    "CLIP=5\n",
    "MODEL_ARCH='LSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERData():\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.words = None\n",
    "        self.tags = None\n",
    "        self.sentences = None\n",
    "        self.vocab_to_int = None\n",
    "        self.tag_to_int = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv('D:/Projects/Sessions/NER/input/ner_dataset.csv',encoding = 'latin1')\n",
    "        self.data = self.data.fillna(method='ffill')\n",
    "        print(\"Unique Words \", self.data['Word'].nunique())\n",
    "        print(\"Unique Tags \", self.data['Tag'].nunique())\n",
    "        self.words = list(set(self.data['Word'].values))\n",
    "        self.tags = list(set(self.data['Tag'].values))\n",
    "        self.words.append('PAD')\n",
    "\n",
    "\n",
    "    def sentence_getter(self):\n",
    "        agg_func = lambda s:[(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                          s[\"POS\"].values.tolist(),\n",
    "                                                          s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "        return self.sentences\n",
    "\n",
    "    def vocab_dict(self):\n",
    "        self.vocab_to_int = {w:i+1 for i,w in enumerate(self.words)}\n",
    "        self.int_to_vocab = {i: w for w, i in self.vocab_to_int.items()}\n",
    "        self.tag_to_int = {w:i for i,w in enumerate(self.tags)}\n",
    "        self.int_to_tag = {i: w for w, i in self.tag_to_int.items()}\n",
    "        return self.vocab_to_int, self.tag_to_int\n",
    "\n",
    "    def encode_text(self):\n",
    "        self.encoded_sentence = []\n",
    "        self.encoded_tag = []\n",
    "        for sentence in self.sentences:\n",
    "            self.encoded_sentence.append([self.vocab_to_int[w[0]] for w in sentence])\n",
    "            self.encoded_tag.append([self.tag_to_int[w[2]] for w in sentence])\n",
    "\n",
    "    def pad_features(self):\n",
    "\n",
    "        self.padded_sentence = np.zeros((len(self.sentences), config.SEQ_LENGTH),dtype=int)\n",
    "        self.padded_tag = np.zeros((len(self.sentences), config.SEQ_LENGTH),dtype=int)\n",
    "\n",
    "        print(\"Padding Sentence\")\n",
    "        for i, row in enumerate(self.encoded_sentence):\n",
    "            self.padded_sentence[i, -len(row):] = np.array(row)[:config.SEQ_LENGTH]\n",
    "        print(\"Padding Tag\")\n",
    "        for i, row in enumerate(self.encoded_tag):\n",
    "            self.padded_tag[i, -len(row):] = np.array(row)[:config.SEQ_LENGTH]\n",
    "\n",
    "    def process_text(self, text):\n",
    "        encoded_text = []\n",
    "        for word in text.split():\n",
    "            code = self.vocab_to_int.get(word)\n",
    "            if code != None:\n",
    "                encoded_text.append(code)\n",
    "\n",
    "        padded_text = np.zeros((1, config.SEQ_LENGTH),dtype=int)\n",
    "        padded_text[0,-len(encoded_text):] = encoded_text\n",
    "\n",
    "        return padded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(encoded_features, encoded_labels):\n",
    "    split_idx = int(len(encoded_features) * config.SPLIT)\n",
    "    train_x, remaining_x = encoded_features[:split_idx], encoded_features[split_idx:]\n",
    "    train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "    test_idx = int(len(remaining_x) * 0.5)\n",
    "    val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "    val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "    ## print out the shapes of your resultant feature data\n",
    "    print(\"\\t\\t\\tFeature Shapes:\")\n",
    "    print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
    "          \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "          \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
    "\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Words  35178\n",
      "Unique Tags  17\n",
      "Padding Sentence\n",
      "Padding Tag\n"
     ]
    }
   ],
   "source": [
    "ner_data = NERData()\n",
    "ner_data.load_data()\n",
    "sentences = ner_data.sentence_getter()\n",
    "vocab_to_int, tag_to_int = ner_data.vocab_dict()\n",
    "ner_data.encode_text()\n",
    "ner_data.pad_features()\n",
    "encoded_features= ner_data.padded_sentence\n",
    "encoded_labels = ner_data.padded_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0, 22217,\n",
       "        7116, 22965, 22326, 18829, 18981, 33587, 34436,  8261, 19864,\n",
       "       10226,  9767,  2677, 26962, 16623, 19864, 24037,  7116, 32800,\n",
       "       15706, 18443, 30545, 33333, 18752])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(38367, 50) \n",
      "Validation set: \t(4796, 50) \n",
      "Test set: \t\t(4796, 50)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, val_x, val_y, test_x, test_y = data_split(encoded_features, encoded_labels)\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=config.BATCH_SIZE,drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=config.BATCH_SIZE,drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=config.BATCH_SIZE,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vocab_size = len(ner_data.vocab_to_int)+1\n",
    "output_size = len(ner_data.tag_to_int)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['vocab_size'] = vocab_size\n",
    "params['output_size'] = output_size\n",
    "params['embedding_dim'] = EMBEDDING_DIM\n",
    "params['lstm_hidden_dim']= HIDDEN_DIM\n",
    "params['n_layers'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        self.output_size = params['output_size']\n",
    "        self.n_layers = params['n_layers']\n",
    "        self.hidden_dim = params['lstm_hidden_dim']\n",
    "        super(Net, self).__init__()\n",
    "        #maps each token to an embedding_dim vector\n",
    "        self.embedding = nn.Embedding(params['vocab_size'], params['embedding_dim'])\n",
    "\n",
    "        #the LSTM takens embedded sentence\n",
    "        self.lstm = nn.LSTM(params['embedding_dim'], params['lstm_hidden_dim'], batch_first=True)\n",
    "\n",
    "        #fc layer transforms the output to give the final output layer\n",
    "        self.fc = nn.Linear(params['lstm_hidden_dim'], params['output_size'])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # apply the embedding layer that maps each token to its embedding\n",
    "        s = self.embedding(x)  # dim: batch_size x batch_max_len x embedding_dim\n",
    "\n",
    "        # run the LSTM along the sentences of length batch_max_len\n",
    "        s, _ = self.lstm(s)  # dim: batch_size x batch_max_len x lstm_hidden_dim\n",
    "\n",
    "        # reshape the Variable so that each row contains one token\n",
    "        # print(\"before \",s.shape)\n",
    "        # s = s.view(-1, s.shape[2])  # dim: batch_size*batch_max_len x lstm_hidden_dim\n",
    "        s = s.reshape(-1, s.shape[2])\n",
    "        # print(\"after \",s.shape)\n",
    "\n",
    "        # apply the fully connected layer and obtain the output for each token\n",
    "        s = self.fc(s)  # dim: batch_size*batch_max_len x num_tags\n",
    "\n",
    "        # s = s.reshape(x.size(0),50, s.shape[2])\n",
    "\n",
    "        return F.log_softmax(s, dim=1)  # dim: batch_size*batch_max_len x num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(35179, 150)\n",
       "  (lstm): LSTM(150, 256, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(35179, 150)\n",
       "  (lstm): LSTM(150, 256, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=0.001\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "net.to(device=config.DEVICE)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, labels):\n",
    "    #reshape labels to give a flat vector of length batch_size*seq_len\n",
    "    labels = labels.view(-1)\n",
    "\n",
    "    #mask out 'PAD' tokens\n",
    "    mask = (labels > 0).float()\n",
    "\n",
    "    #the number of tokens is the sum of elements in mask\n",
    "    num_tokens = int(torch.sum(mask).item())\n",
    "    #pick the values corresponding to labels and multiply by mask\n",
    "\n",
    "    outputs = outputs[range(outputs.shape[0]), labels]*mask\n",
    "\n",
    "    #cross entropy loss for all non 'PAD' tokens\n",
    "    return -torch.sum(outputs)/num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, valid_loader, model, optimizer, device):\n",
    "\n",
    "    for e in range(config.EPOCHS):\n",
    "        counter = 0\n",
    "        for inputs, labels in data_loader:\n",
    "            model.train()\n",
    "            counter += 1\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            model.zero_grad()\n",
    "            inputs = inputs.long()\n",
    "            labels = labels.long()\n",
    "            output= model(inputs)\n",
    "\n",
    "            loss = loss_fn(output, labels)\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), config.CLIP)\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss stats\n",
    "            if counter % config.PRINT_EVERY == 0:\n",
    "                # Get validation loss\n",
    "                val_losses = []\n",
    "                model.eval()\n",
    "                for val_inputs, val_labels in valid_loader:\n",
    "                    val_inputs, val_labels = val_inputs.to(config.DEVICE), val_labels.to(config.DEVICE)\n",
    "                    val_inputs = val_inputs.long()\n",
    "                    val_labels = val_labels.long()\n",
    "                    output = model(val_inputs)\n",
    "                    output = output.to(config.DEVICE)\n",
    "                    # output = model(inputs)\n",
    "                    val_loss = loss_fn(output, val_labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                model.train()\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, config.EPOCHS),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.995073... Val Loss: 1.068169\n",
      "Epoch: 1/4... Step: 200... Loss: 0.832875... Val Loss: 0.838384\n",
      "Epoch: 1/4... Step: 300... Loss: 0.836846... Val Loss: 0.738358\n",
      "Epoch: 2/4... Step: 100... Loss: 0.576773... Val Loss: 0.633245\n",
      "Epoch: 2/4... Step: 200... Loss: 0.423081... Val Loss: 0.605756\n",
      "Epoch: 2/4... Step: 300... Loss: 0.564061... Val Loss: 0.576240\n",
      "Epoch: 3/4... Step: 100... Loss: 0.309191... Val Loss: 0.554033\n",
      "Epoch: 3/4... Step: 200... Loss: 0.350453... Val Loss: 0.547461\n",
      "Epoch: 3/4... Step: 300... Loss: 0.448983... Val Loss: 0.540254\n",
      "Epoch: 4/4... Step: 100... Loss: 0.304602... Val Loss: 0.534080\n",
      "Epoch: 4/4... Step: 200... Loss: 0.297349... Val Loss: 0.528012\n",
      "Epoch: 4/4... Step: 300... Loss: 0.362707... Val Loss: 0.530787\n"
     ]
    }
   ],
   "source": [
    "net = train_fn(train_loader, valid_loader, net, optimizer, config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_object, input):\n",
    "\n",
    "    padded_input = data_object.process_text(input)\n",
    "    padded_input = torch.from_numpy(padded_input)\n",
    "\n",
    "    # padded_input = data_object.padded_sentence[0]\n",
    "    # padded_input = torch.from_numpy(padded_input)\n",
    "    padded_input = padded_input.reshape(-1, 50)\n",
    "    padded_input = padded_input.long()\n",
    "    padded_input = padded_input.to(config.DEVICE)\n",
    "    output = model(padded_input)\n",
    "    ind = torch.max(output, dim=1).indices.detach().cpu().numpy()\n",
    "    tags = \" \".join(data_object.int_to_tag[x] for x in ind)\n",
    "\n",
    "    output_sentence = []\n",
    "    for w, i in zip(padded_input.cpu().detach().numpy()[0], ind):\n",
    "        if w != 0:\n",
    "            output_sentence.append((data_object.int_to_vocab[w] + '(' + data_object.int_to_tag[i]) + ')')\n",
    "\n",
    "    sent = \" \".join(x for x in output_sentence)\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-geo',\n",
       " 2: 'B-eve',\n",
       " 3: 'I-art',\n",
       " 4: 'B-gpe',\n",
       " 5: 'B-art',\n",
       " 6: 'I-gpe',\n",
       " 7: 'I-tim',\n",
       " 8: 'I-org',\n",
       " 9: 'I-per',\n",
       " 10: 'B-org',\n",
       " 11: 'B-tim',\n",
       " 12: 'I-nat',\n",
       " 13: 'I-eve',\n",
       " 14: 'B-per',\n",
       " 15: 'B-nat',\n",
       " 16: 'I-geo'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data.int_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands(B-per) of(I-org) demonstrators(B-per) have(B-geo) marched(B-per) through(B-tim) London(B-geo) to(B-tim) protest(B-geo) the(B-geo) war(B-org) in(B-tim) Iraq(B-geo) and(I-geo) demand(B-geo) the(B-geo) withdrawal(B-org) of(B-tim) British(B-gpe) troops(I-org) from(B-tim) that(B-geo)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \" Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country.\"\n",
    "predict(net, ner_data, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The(B-org) Boeing(B-org) Company(I-org) is(B-geo) a(B-geo) great(B-tim) organization(I-tim) and(I-tim) David(B-per) is(I-per) its(B-tim) CEO(B-gpe)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \" Iraq demanded withdrawal of British troops. China also extended their support to Iran and Iraq\"\n",
    "predict(net, ner_data, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The(B-org) Boeing(B-org) Company(I-org) is(B-geo) a(B-geo) great(B-tim) organization(I-tim) and(I-tim) David(B-per) is(I-per) its(B-tim) CEO(B-gpe)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \" The Boeing Company is a great organization and David Calhoun is its CEO\"\n",
    "predict(net, ner_data, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
